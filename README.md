# MyResume

Generative AI/ML Software Developer as a trusted partner to enable customer success at scale

## HIGHLIGHTS
•	Proven experience as ML developer in building and architecting software with customers

•	Own and drive full stack transition from data science PoC to large-scale virtualization and deployment of generative AI models (LSTM, CNN, DNN, RNN, GAN, AutoEncoders, deep learning, BERT transformers, generative AI, GPT, Llama, LLM, Stable Diffusion)

•	Expert knowledge and experience in deep earning to Generative AI model development and deployment cycles. 

•	Growth mindset and self starter with multiple professional certificates including CUDA C++ certification.

•	Hands-on fast learner with can-do attitude, with two Tensorflow+GCP books

•	Hands-on experience with NVIDIA GPU (ie, A10G, A100) and Tools (Nsights, Triton, CUDA, TensorRT) and AWS Trainium, deep understanding of GPU technologies.

•	Expertise in optimization of deep learning, transformers, LLM and generative AI models for public cloud and distributed architecture

•	Experience with major Cloud platforms (AWS, Azure, GCP).

•	Author, public speaker, mentor and open source ecosystem contributor in building infrastructure and code samples to enable generative AI workloads


## WORK EXPERIENCES

### J.P.Morgan      - Vice President, Lead AI/ML Engineering. 4/2025 - Present

- Lead the end-to-end design, development, and production deployment of generative AI applications, ensuring scalability, reliability, and alignment with long-term business goals.  

- Define and execute progressive delivery strategies, including controlled rollouts and A/B testing frameworks to deliver measurable product impact.  

- Manage infrastructure-as-code pipelines and CI/CD workflows to enable secure, repeatable deployment of LLM applications (e.g., MPT, Falcon) in production environments.  

- Own model governance processes, including data usage audits and compliance reviews, to ensure adherence to AI safety standards and regulatory requirements.  

- Champion cross-functional collaboration across engineering, product, compliance, and risk to deliver robust, enterprise-grade AI solutions with built-in exception handling.  

- Mentor junior engineers, cultivate a culture of experimentation and continuous learning, and promote team effectiveness through technical leadership and knowledge sharing.




### Amazon AWS		- ML Accelerator Development Engineer, AI Architect	7/2021 – 3/2024

•	Lead and partner with customer to prototype, develop and deploy generative AI solutions using AWS Trainium and Inferentia accelerators for wide range of generative AI models (deep learning, BERT transformers, generative AI, GPT, Llama, LLM, Stable Diffusion) at scale. 

•	Collaborate in cross-functional teams and build AI/ML solutions on AWS services, HPC/ParallelCluster, Docker containers, and Kubernetes orchestration.

•	Lead and drive insight discovery in ML model profiling analysis using NVIDIA GPUs (A10G, A100G) and Nsights, Triton, and TensorRT.

•	Collaborate with customers and stakeholders on requirement and features, ensure success criteria, own customer feedback channels and ensure timely resolutions.

•	Drive the architecture and implementation of model deployment strategies, for high availability and scalability

•	 Collaborate with QA team to improve CI/CD pipelines for seamless model deployment, monitoring, and ongoing optimization. 

•	Establish performance benchmarks and optimize models and infrastructure for maximum efficiency, scalability, and reliability. 

•	Stay at the forefront of industry trends and emerging technologies, integrating the latest advancements into ML ecosystem.


### Microsoft	- ML Engineer, AI Architect		11/2018 – 07/2021

•	Collaborate with customer to build and deploy deep learning ML models utilizing TensorFlow, Spark, AzureML services and Azure Kubernetes Service.

•	Collaborate with WW AI Champs to draft and publish the first Cloud Adoption Framework – Machine Learning Security best practice for machine learning security in enterprise settings.

•	Conduct literature research, collaborate with WW SMEs and PMs on solving customer's data science problems for specialized use case.

•	Partner with customer engineering team to develop machine learning solutions and architecture pipeline for data transformation and model deployment in Azure.

•	Design PoC specific to customer use cases, develop solution prototype and up skill customer team via hands-on workshop for realizing solution value.

•	Provide technical leadership as a trusted data & AI adviser to customer teams of data scientists, engineers, and analysts, help them select and adopt feasible techniques and scalable solutions for specific business use cases.

•	Serve as reviewer for MSJAR.


### AT&T	-Principal Data Scientist		03/2014 – 10/2018

•	Adopted deep learning (LSTM, CNN) techniques as an innovative solution to solve customer 
touchpoint prediction problem and enable data driven conversion funnel as a service for advertisers.

•	Established best-practice strategy for data scientists, engineers and process owners to design scalable and production grade solutions in agile development environment.

•	Translated user stories and business requirements to hypothesis for AI/ML models and designed end-to-end model solution architecture.

•	Collaborated with industry thought leaders to evaluate data science platforms and vendors.

•	Led, mentored, and developed strong data science and engineering talent in cross functional team environment.


## SOFTWARE AND PLATFORM
•	AWS, GCP, Azure, Databricks, Docker Container ecosystem, Kubernetes orchestration, MLOps, HPC, PyTorch, TensorFlow, TensorRT, CUDA, Triton Inferencing Server, FastAPI, TensorFlow Serving, AWS Neuron SDK, distributed ML training and inferencing, C, C++, C#, Python and packages, Java, Javascript, Spark, Hadoop, Big Data ETL, Hive, SQL, R, Matlab.

## EDUCATION
Ph.D., Computational Biophysics, University of Texas Southwestern Medical Center, Dallas TX. Dissertation: Human brain's neural network and synchronization activities (https://pubmed.ncbi.nlm.nih.gov/23583747/)

B.S., Electrical Engineering, University of Texas at Arlington, Arlington TX.


## CERTIFICATION
•	Microsoft Azure Certified AI Engineer, Data Engineer, Database Administrator, AI Ambassador.

•	Microsoft Certified Enterprise Data Scientist.

•	Microsoft OpenHack Coach: Knowledge Mining, Modern Data Warehousing, DevOps for Data Science.

•	Microsoft GSMO Manufacturing EOU's AI Champ.

•	Microsoft Research AI School AI-611 Project MIKROS team member

## BOOKS and BLOGS

•	Learn TensorFlow Enterprise with Google Cloud AI Platform. Packt Publishing, 2020. https://a.co/d/dVdL29h

•	TensorFlow 2 Pocket Reference. O’Reilly Publishing, 2021. https://a.co/d/fuUbFhY

•	Scaling Large Language Model (LLM) training with Amazon EC2 Trn1 UltraCluster. 2023

•	Maximize Stable Diffusion performance and lower inference costs with AWS Inferentia2. 2023

•	Optimize AWS Inferentia utilization with FastAPI and PyTorch models on Amazon EC2 Inf1 & Inf2 instances. 2023

•	Research and develop novel techniques to measure machine learning training data similarity. Pure AI, 2021

## CONFERENCES

•	AWS Re:Invent 2022, 2023 workshop: Stable Diffusion and Vision Transformers deployment on AWS

•	A novel solution for data augmentation in NLP using TensorFlow. TensorFlow World. 2019. Santa Clara.

•	A novel adoption of LSTM in customer touchpoint prediction problems. O’Reilly AI Conference. 2018. San Francisco.

## GITHUB
•	Main page: https://github.com/isaid22 

•	Book: https://github.com/PacktPublishing/Learn-TensorFlow-Enterprise

    Learn Tensorflow Enterprise : https://a.co/d/dVdL29h

    Tensorflow 2 Pocket Reference : https://a.co/d/fuUbFhY

•	Containerization: [link to examples](https://github.com/isaid22/Tensorflow-Neuronx-Dockerfile)

•	CUDA examples: [link to CUDA examples](https://github.com/isaid22/Tensorflow-Neuronx-Dockerfile)

•	Nvidia Nsight: [link to profiling a model in GPU](https://github.com/isaid22/Profiling-TensorRT-Model-with-Nvidia-Nsight-Systems)

•	Nvidia Nsight setup:[link to Nsight setup](https://github.com/isaid22/Nvidia-Nsight-Systems-Setup)

•	Nvidia Triton Server: [link to Triton Server setup](https://github.com/isaid22/Triton-Server-on-Inferentia)

•	Training LLM with Slurm Cluster using AWS ParallelCluster: [link to setup](https://github.com/aws-neuron/aws-neuron-parallelcluster-samples)


## PATENT
•	[Velocity-weighted analysis of user equipment location data]('http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&r=1&f=G&l=50&co1=AND&d=PTXT&s1=%22velocity+weighted%22&s2=10097960.PN.&OS=') - US10097960, Oct 9, 2018


